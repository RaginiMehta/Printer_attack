{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b2a44142-7319-4c93-b504-91f6cee279aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the task of this script is to: \n",
    "# 1. generate ALL fetaures of the image\n",
    "# 2. store in  file location as .npz\n",
    "# 3. check final dimension and see if it is loading for later classifying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "87907ba3-d1fc-4f79-af31-972ec5a345b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "47b4942b-fe2a-4b29-9819-c3b0f13c1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get region of interest ROI\n",
    "def extract_roi(img, threshold):\n",
    "    if len(img.shape) != 2:\n",
    "        raise ValueError(\"Input image must be grayscale\")\n",
    "    roi_mask = (img < threshold).astype(np.uint8)\n",
    "    return roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4b988b29-2a5c-4714-bf54-b7d5fd58c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get e's extracted\n",
    "\n",
    "def get_e(image_path, crop, op_dir):\n",
    "    # Load the image\n",
    "    # image_path = 'test_images/test_0.png'  # Replace with your image\n",
    "    img1 = cv2.imread(image_path)\n",
    "    img2 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #upscalling images, solely to help tesseract, image extraction will be done from the og image\n",
    "    # img = cv2.resize(img2, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.resize(img2, (img1.shape[1], img1.shape[0]), interpolation=cv2.INTER_CUBIC)   # this is the processed image which \n",
    "                                                                                           # we put in the tesseract\n",
    "                                                                                           # coz it needs clearer pcitures to \n",
    "                                                                                           # accurately locate the e's\n",
    "    # print(img.shape, img2.shape)\n",
    "    \n",
    "    # Get image height (Tesseract origin is bottom-left)\n",
    "    h, w = img.shape\n",
    "    \n",
    "    # op_dir = 'saved_e'\n",
    "    os.makedirs(op_dir, exist_ok=True)\n",
    "    \n",
    "    # Draw setup\n",
    "    # draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Get character bounding boxes\n",
    "    boxes = pytesseract.image_to_boxes(img)\n",
    "    count = 0\n",
    "    \n",
    "    #set dimensions of the boxes \n",
    "    # crop = 14\n",
    "    half = crop//2\n",
    "    \n",
    "    # Draw green dots on top of each 'e'\n",
    "    for b in boxes.strip().splitlines():\n",
    "        b = b.split()\n",
    "        char, x1, y1, x2, y2 = b[0], int(b[1]), int(b[2]), int(b[3]), int(b[4])\n",
    "        \n",
    "        # Flip y-coordinates\n",
    "        y1_new = h - y1\n",
    "        y2_new = h - y2\n",
    "        # cx = (x1 + x2) // 2\n",
    "        # cy = (y1_new + y2_new) // 2\n",
    "    \n",
    "        # make a bounding box around the e\n",
    "        cv2.rectangle(img, (x1, y2_new), (x2, y1_new), (255, 0, 0), 1)\n",
    "    \n",
    "        if char.lower() == 'e' and count<10:\n",
    "    \n",
    "            # compute center of bounding box    \n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1_new + y2_new) // 2\n",
    "        \n",
    "            # Get top-left and bottom-right coordinates of fixed crop\n",
    "            x_start = max(0, cx - half)\n",
    "            y_start = max(0, cy - half)\n",
    "            x_end = min(img2.shape[1], cx + half)\n",
    "            y_end = min(img2.shape[0], cy + half)\n",
    "    \n",
    "            # crop image\n",
    "            cropped = img2[y_start:y_end, x_start:x_end]\n",
    "    \n",
    "            # if dimensions okay, at image to output dir, \n",
    "            # later make sure that the image dirs are constant, else will cause computation error\n",
    "            if cropped.shape[0] > 0 and cropped.shape[1] > 0:\n",
    "                out_path = os.path.join(op_dir, f\"e_{count+1}.png\")\n",
    "                cv2.imwrite(out_path, cropped)\n",
    "                count += 1\n",
    "    \n",
    "    cv2.imwrite(\"output_with_boxes.png\", img)\n",
    "    print(f\"Saved {count} 'e' characters in '{op_dir}/' and annotated image as 'output_with_boxes.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7fdcf003-9ab8-4c4e-88e3-257da3a3c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 'e' characters in '/home/raginivi/Desktop/CV_project/saved_e/1/' and annotated image as 'output_with_boxes.png'\n",
      "Saved 10 'e' characters in '/home/raginivi/Desktop/CV_project/saved_e/2/' and annotated image as 'output_with_boxes.png'\n",
      "Saved 10 'e' characters in '/home/raginivi/Desktop/CV_project/saved_e/3/' and annotated image as 'output_with_boxes.png'\n"
     ]
    }
   ],
   "source": [
    "get_e('test_images/test_0.png',14, '/home/raginivi/Desktop/CV_project/saved_e/1')\n",
    "get_e('test_images/test_6.jpg',14, '/home/raginivi/Desktop/CV_project/saved_e/2')\n",
    "get_e('test_images/test_2.png',10, '/home/raginivi/Desktop/CV_project/saved_e/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b09310ce-99f5-4d78-aa67-7d91599a26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL NORMAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "63790c86-9c1d-4fa8-8f53-253376b2e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_variance(img, roi_mask):\n",
    "    roi_indices = np.where(roi_mask)\n",
    "    roi_pixels = img[roi_indices]\n",
    "    R = len(roi_pixels)\n",
    "    if R == 0:\n",
    "        return 0\n",
    "    mu = np.mean(roi_pixels)\n",
    "    variance = np.sum((roi_pixels - mu)**2)/R # variance\n",
    "    return variance\n",
    "\n",
    "\n",
    "def compute_entropy(img, roi_mask):\n",
    "    roi_indices = np.where(roi_mask)\n",
    "    roi_pixels = img[roi_indices]\n",
    "    R = len(roi_pixels)\n",
    "    if R == 0:\n",
    "        return 0\n",
    "\n",
    "    hist, _ = np.histogram(roi_pixels, bins=256, range=(0, 255)) # probability density function\n",
    "    p = hist / R  # p_Img(alpha)\n",
    "    entropy = -np.sum(p * np.log2(p + 1e-10)) # this is added to avoid log 0 ...can think of it as a small value epsilon\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e4bf7758-aa2b-4d47-968d-834937bfd09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL GLCM FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0145b48c-c671-4234-b4fe-d17ac5e21a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glcm(img_path, dist, levels):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Quantize to 8 gray levels (0 to 7)\n",
    "    levels = 256\n",
    "    # quantized = (gray / (256 // levels)).astype(np.uint8)\n",
    "\n",
    "    distance = list(range(1, dist+1))\n",
    "    # R = roi(gray, 256)\n",
    "    \n",
    "    # Compute GLCM\n",
    "    glcm = graycomatrix(gray, distances=distance, angles=[0], levels=levels, symmetric=False, normed=True)\n",
    "    \n",
    "    # display GLCM matrix for angle=0 and distance=1\n",
    "    # print(glcm[:, :, 0, 0])\n",
    "    n_glcm = glcm[:,:,:,0]  #//R \n",
    "    # print(n_glcm)\n",
    "    return n_glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8c645f73-89c1-46f0-b534-ab10c2ae792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(arr,ch):\n",
    "    # print(arr.shape)\n",
    "    if ch == 'c':\n",
    "        c = np.sum(arr, axis=0, keepdims=True)\n",
    "        # print(\"Shape is:\", c.shape)\n",
    "        return c\n",
    "    elif ch == 'r':\n",
    "        r = np.sum(arr, axis=1, keepdims=True) \n",
    "        # print(\"Shape is:\", r.shape)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c01292ab-8cdb-4bb2-8b57-30d5a2466a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var(arr, mean):\n",
    "    m, n, d = arr.shape\n",
    "\n",
    "    if m!=1 and n ==1: \n",
    "        a = m\n",
    "        axis = 0\n",
    "    elif n!=1 and m ==1: \n",
    "        a = n\n",
    "        axis = 1\n",
    "    else: print(\"not valid state\")\n",
    "\n",
    "    var = np.zeros((1,1,d))\n",
    "    mean = mean.flatten()\n",
    "    \n",
    "    for i in range(d):\n",
    "        summ = 0\n",
    "        for j in range(a):\n",
    "            val = arr[j, 0, i] if axis == 0 else arr[0, j, i]\n",
    "            summ += (j ** 2) * val\n",
    "        var[0, 0, i] = summ - mean[i]\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "23657814-386f-4bba-bd1f-46f485cdbc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(arr):\n",
    "    '''input GLCM matirx, normalized'''\n",
    "    m,n,d = arr.shape\n",
    "    e = np.zeros(d)\n",
    "    \n",
    "    for i in range(d):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                e[i] = e[i] + (arr[j,k,i]**2)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d75b59d4-c062-4950-8231-7c84fb0e0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy1(arr, ar, ac):\n",
    "    '''input GLCM matirx, normalized, mean_row and mean_column'''\n",
    "    m, n, d = arr.shape\n",
    "    \n",
    "    m1, n1, d = ar.shape\n",
    "    if n1!=1: print(\"Nope, shape of ar is not correct\")\n",
    "                    \n",
    "    m2, n2, d = ac.shape\n",
    "    if m2!=1: print(\"Nope, chape of ac is not correct\")\n",
    "\n",
    "    # for k in range(d):\n",
    "    # summ = np.zeros(d)        \n",
    "    #     for i in range(m1):\n",
    "    #         for j in range(n2):\n",
    "    #             summ[i][1][d] = summ[][][d] + arr[i][j][d]*np.log(ar[m][1]*ac[1][n])\n",
    "\n",
    "    summ = np.zeros(d)\n",
    "    for k in range(d):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                p = arr[i, j, k]\n",
    "                pr = ar[i, 0, k]\n",
    "                pc = ac[0, j, k]\n",
    "                if p > 0 and pr > 0 and pc > 0:\n",
    "                    summ[k] += p * np.log(pr * pc)\n",
    "    \n",
    "    return -1*summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9bcbda24-a016-4399-b110-bfcad7cc3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy2(ar, ac):\n",
    "    '''input mean row and mean column'''\n",
    "    m1, n1, d = ar.shape\n",
    "    if n1!=1: print(\"Nope, shape of ar is not correct\")\n",
    "                    \n",
    "    m2, n2, d = ac.shape\n",
    "    if m2!=1: print(\"Nope, chape of ac is not correct\")\n",
    "\n",
    "    # for k in range(d):\n",
    "    # summ = np.zeros(d)        \n",
    "    #     for i in range(m1):\n",
    "    #         for j in range(n2):\n",
    "    #             summ[i][1][d] = summ[][][d] + arr[i][j][d]*np.log(ar[m][1]*ac[1][n])\n",
    "\n",
    "\n",
    "    summ = np.zeros(d)\n",
    "    for k in range(d):\n",
    "        # summ = 0\n",
    "        for i in range(m1):\n",
    "            for j in range(n2):\n",
    "                if ar[i, 0, k] * ac[0, j, k]> 0:\n",
    "                    summ[k] = summ[k] + ar[i, 0, k] * ac[0, j, k] * np.log(ar[i, 0, k] * ac[0, j, k])\n",
    "    \n",
    "                \n",
    "    return -1*summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1aeff5a7-4b30-4816-927f-8e9b6d070807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy3(arr):\n",
    "    '''input GLCM matirx, normalized <<--'''\n",
    "    m, n, d = arr.shape\n",
    "    \n",
    "    # for k in range(d):\n",
    "    # summ = np.zeros(d)        \n",
    "    #     for i in range(m1):\n",
    "    #         for j in range(n2):\n",
    "    #             summ[i][1][d] = summ[][][d] + arr[i][j][d]*np.log(ar[m][1]*ac[1][n])\n",
    "\n",
    "    summ = np.zeros(d)\n",
    "    for k in range(d):\n",
    "        # summ = 0\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if arr[i,j,k]>0:\n",
    "                    summ[k] = summ[k] + arr[i,j,k]*np.log(arr[i,j,k])\n",
    "    \n",
    "    return -1*summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "428b8589-5785-43db-a95d-1e4319885705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_prob(arr):\n",
    "    '''input GLCM matirx, normalized'''\n",
    "    m, n, d = arr.shape\n",
    "\n",
    "    mP = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        mP[i] = np.max(arr[:,:,i])\n",
    "\n",
    "    return mP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fd054a73-ca71-4f1f-a80e-4b809698a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_haralicks(arr, ur, uc, var_r, var_c, eps = 1e-8):\n",
    "    '''input GLCM matirx, normalized, \n",
    "    mean row and mean column,\n",
    "    variance row and variance column,\n",
    "    and epsilon value to prevent denom form goint 0'''\n",
    "    m, n, d = arr.shape\n",
    "\n",
    "    arr = arr.astype(np.float64)\n",
    "    ur = ur.astype(np.float64)\n",
    "    uc = uc.astype(np.float64)\n",
    "    var_r = var_r.astype(np.float64)\n",
    "    var_c = var_c.astype(np.float64)\n",
    "\n",
    "    h = np.zeros(d)\n",
    "\n",
    "    for k in range(d):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                h[k] += (i - ur[0,0,k])*(j - uc[0,0,k])*arr[i,j,k]/(np.sqrt(var_r[0,0,k]*var_c[0,0,k]) + eps)\n",
    "    \n",
    "    # print(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "57257474-e784-45c1-9b43-78164037854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dCorr(arr, ur, uc):\n",
    "    '''input GLCM matirx, normalized,\n",
    "    mean row and mean column'''\n",
    "    m,n,d = arr.shape\n",
    "\n",
    "    arr = arr.astype(np.float64)\n",
    "    ur = ur.astype(np.float64)\n",
    "    uc = uc.astype(np.float64)\n",
    "    \n",
    "    dC = np.zeros(d)\n",
    "\n",
    "    for k in range(d):\n",
    "        mu_r = ur[0, 0, k]\n",
    "        mu_c = uc[0, 0, k]\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                dC[k] += abs(i - j) * (i + j - mu_r - mu_c) * arr[i, j, k]\n",
    "\n",
    "    return dC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b8071693-2c1b-421d-9c78-0f7edce8c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_D_k(arr):\n",
    "    ''' output is (max_diff+1, d) array, where each D[k] is a sum over |n - m| = k'''\n",
    "    \n",
    "    m, n, d = arr.shape\n",
    "\n",
    "    md = max(m, n) - 1\n",
    "\n",
    "    D_k = np.zeros((md+1, d))\n",
    "    for k in range(d):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                diff = np.abs(i - j)\n",
    "                D_k[diff, k] += arr[i,j,k]\n",
    "\n",
    "    return D_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6e9dbd1f-76ad-4c6d-87ea-a4fe54680300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Denergy(arr):\n",
    "    return np.sum(arr, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "91b772c6-3bd7-41f5-be58-14a10e5cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dentropy3(arr):\n",
    "    '''input GLCM matrix, normalized <-'''\n",
    "    m, d= arr.shape\n",
    "    \n",
    "    # for k in range(d):\n",
    "    # summ = np.zeros(d)        \n",
    "    #     for i in range(m1):\n",
    "    #         for j in range(n2):\n",
    "    #             summ[i][1][d] = summ[][][d] + arr[i][j][d]*np.log(ar[m][1]*ac[1][n])\n",
    "\n",
    "    summ = np.zeros(d)\n",
    "    for k in range(d):\n",
    "        # summ = 0\n",
    "        for i in range(m):\n",
    "                if arr[i,k]>0:\n",
    "                    summ[k] = summ[k] + arr[i,k]*np.log(arr[i,k])\n",
    "    \n",
    "    return -1*summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6d10014f-bd95-4cf6-ac17-0821f6b8dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inertia(D_k):\n",
    "    \n",
    "    k = np.arange(D_k.shape[0])[:, np.newaxis]  # shape (256, 1)\n",
    "    ID = np.sum((k**2) * D_k, axis=0)  # sum over k for each distance\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "64864f06-c163-4c2f-bd80-30a21dd61cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hD(D_k):\n",
    "    \n",
    "    k = np.arange(D_k.shape[0])[:, np.newaxis]  # shape (256, 1)\n",
    "    hD = np.sum(D_k / (1 + k**2), axis=0)\n",
    "    return hD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f3bad396-52fb-489e-a622-390ad7fe42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_S_k(arr):\n",
    "    ''' output is (max_diff+1, d) array, where each D[k] is a sum over |n - m| = k'''\n",
    "    \n",
    "    m, n, d = arr.shape\n",
    "\n",
    "    ms = m+n-2\n",
    "\n",
    "    S_k = np.zeros((ms+1, d))\n",
    "    for k in range(d):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                summ = i + j\n",
    "                S_k[summ, k] += arr[i,j,k]\n",
    "\n",
    "    return S_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4db47b3a-e6c3-40ff-879d-3792c1f21240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_S(S_k):\n",
    "    ks = np.arange(S_k.shape[0])  # array of k from 0 to 510\n",
    "    mu_S = np.sum(ks[:, None] * S_k, axis=0)  # shape: (d,)\n",
    "    return mu_S.reshape(1, -1)  # shape (1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e72e0b06-990a-4a1f-ba6b-58847fde6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(S_k, mu_S):\n",
    "    k = np.arange(511).reshape(-1, 1)  # shape (512, 1)\n",
    "    result = np.sum(((k - mu_S) ** 2) * S_k, axis=0)\n",
    "    return result.reshape(1, -1)  # shape (1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "25277d31-a706-4839-b848-c2f8f24a884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A_B_d(S_k, mu_r, mu_c, sigma_r, sigma_c):\n",
    "    m, d = S_k.shape  # e.g., (510, 10)\n",
    "    k = np.arange(m).reshape(-1, 1)  # shape (510, 1)\n",
    "\n",
    "    mu_r = mu_r.reshape(1, 10)\n",
    "    mu_c = mu_r.reshape(1, 10)\n",
    "    sigma_r = mu_r.reshape(1, 10)\n",
    "    sigma_c = mu_r.reshape(1, 10)\n",
    "\n",
    "    # print(mu_r.shape, mu_c.shape, sigma_r.shape, sigma_c.shape)\n",
    "    AD = np.zeros((1, d))\n",
    "    BD = np.zeros((1, d))\n",
    "\n",
    "    for l in range(d):\n",
    "        # Extract scalars from 1x10 inputs\n",
    "        mu_r_l = float(mu_r[0, l])\n",
    "        mu_c_l = float(mu_c[0, l])\n",
    "        sigma_r_l = float(sigma_r[0, l])\n",
    "        sigma_c_l = float(sigma_c[0, l])\n",
    "\n",
    "        diff = k - mu_r_l - mu_c_l  # shape (510, 1)\n",
    "        denom = sigma_r_l**2 + sigma_c_l**2 + 2 * sigma_r_l * sigma_c_l\n",
    "        if denom == 0:\n",
    "            denom = 1e-10\n",
    "\n",
    "        AD[0, l] = np.sum((diff.flatten() ** 3) * S_k[:, l]) / (denom ** 1.5)\n",
    "        BD[0, l] = np.sum((diff.flatten() ** 4) * S_k[:, l]) / (denom ** 2)\n",
    "\n",
    "    return AD, BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a93d0e01-7d6f-419a-be1c-0c24cb5a552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL DFT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4ec180ca-6fd4-48a5-a5df-3679f3fb8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_projection(img, roi_mask):\n",
    "    proj = np.sum(img * roi_mask, axis = 1)\n",
    "    norm = np.sum(roi_mask, axis = 1)\n",
    "    b = np.zeros_like(proj, dtype=float)\n",
    "    for i in range(len(b)):\n",
    "        if norm[i]>0:\n",
    "            b[i] = proj[i]/norm[i]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b6491e90-4d9f-4ee8-ab8a-bf586602809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft_features(b):\n",
    "    \"\"\"More direct implementation of Equation 6\"\"\"\n",
    "    if len(b) < 240:\n",
    "        b_padded = np.pad(b, (0, 240 - len(b)), mode='constant')\n",
    "    else:\n",
    "        b_padded = b[:240]\n",
    "    \n",
    "    N = 240\n",
    "    features = np.zeros(15)\n",
    "    \n",
    "    # Frequencies centered at [10,20,...,150] cycles/inch\n",
    "    for i in range(15):\n",
    "        n = (i + 1) * 10  # 10,20,...,150\n",
    "        # Calculate the DFT at frequency n\n",
    "        dft_val = 0\n",
    "        for k in range(N):\n",
    "            dft_val += b_padded[k] * np.exp(-1j * 2 * np.pi * n * k / N)\n",
    "        features[i] = np.abs(dft_val)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "84e5a02d-a12c-47e2-a836-13b5f5f9da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a final feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d4302160-952e-419b-a749-4bee1c15d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a complete glcm feature \n",
    "\n",
    "def get_all_glcm_features(img_path, dist, levels):\n",
    "    featurs = []\n",
    "\n",
    "    # basic glcm features x 4\n",
    "    s1 = glcm(img_path, dist, levels)\n",
    "    s11 = get_sum(s1, 'r')\n",
    "    s12 = get_sum(s1, 'c')\n",
    "    s111 = get_sum(s11, 'c').reshape(1, 10) #\n",
    "    # print(\"s111\", s111.shape)\n",
    "    s112 = get_sum(s12, 'r').reshape(1, 10) #\n",
    "    # print(\"s112\", s112.shape)\n",
    "    s13 = get_var(s11, s111).reshape(1, 10)#\n",
    "    # print(\"s13\", s13.shape)\n",
    "    s14 = get_var(s12, s112).reshape(1, 10) #\n",
    "    # print(\"s14\", s14.shape)\n",
    "    \n",
    "    # 2nd level of features x 7\n",
    "    s21 = get_energy(s1).reshape(1, 10) #\n",
    "    # print(\"s21\", s21.shape)\n",
    "    s22 = get_entropy1(s1, s11, s12) #\n",
    "    s23 = get_entropy2(s11, s12) #\n",
    "    s24 = get_entropy3(s1) #\n",
    "\n",
    "    s25 = max_prob(s1) #\n",
    "    s26 = get_haralicks(s1, get_sum(s11, 'c'), get_sum(s12, 'r'), get_var(s11, s111), get_var(s12, s112)) #\n",
    "    s27 = get_dCorr(s1, get_sum(s11, 'c'), get_sum(s12, 'r')) #\n",
    "\n",
    "    # differnce hist features x 4\n",
    "    d1 = get_D_k(s1)\n",
    "    d11 = get_Denergy(d1) #\n",
    "    d12 = get_Dentropy3(d1) #\n",
    "    d13 = get_inertia(d1) #\n",
    "    d14 = get_hD(d1) #\n",
    "\n",
    "    # sum hist features x 5\n",
    "    m1 = get_S_k(s1)\n",
    "    m2 = mean_S(m1)\n",
    "    m11 = get_Denergy(m1) #\n",
    "    m12 = get_Dentropy3(m1) #\n",
    "    m13 = get_sigma(m1, m2) #\n",
    "    # m14 = get_A_D(m1, get_sum(s11, 'c'), get_sum(s12, 'r'), np.sqrt(get_var(s11, s111)), np.sqrt(get_var(s12, s112))) #\n",
    "    # print(\"m14\", m14.shape)\n",
    "    # m15 = get_B_D(m1, get_sum(s11, 'c'), get_sum(s12, 'r'), np.sqrt(get_var(s11, s111)), np.sqrt(get_var(s12, s112))) #\n",
    "    # print(\"m15\", m15.shape)\n",
    "    m14, m15 = get_A_B_d(m1, get_sum(s11, 'c'), get_sum(s12, 'r'), np.sqrt(get_var(s11, s111)), np.sqrt(get_var(s12, s112)))\n",
    "    \n",
    "    feature_vector = [s111, s112, s13, s14, s21, s22, s23, s24, s25, s26, s27, d11, \n",
    "                      d12, d13, d14, m11, m12, m13, m14, m15]\n",
    "\n",
    "    final_vector = np.vstack(feature_vector) \n",
    "    return final_vector\n",
    "    # print(final_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dc22bdc5-b5b9-4c91-88c9-9c76b09bc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "Extracted GLCM feature vector: [[1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "  1.000e+00 1.000e+00 1.000e+00]\n",
      " [1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "  1.000e+00 1.000e+00 1.000e+00]\n",
      " [4.738e+04 4.594e+04 4.632e+04 4.729e+04 4.733e+04 4.670e+04 4.588e+04\n",
      "  4.475e+04 4.428e+04 4.640e+04]\n",
      " [4.534e+04 4.393e+04 4.469e+04 4.688e+04 4.812e+04 4.824e+04 4.761e+04\n",
      "  4.681e+04 4.570e+04 4.538e+04]\n",
      " [1.919e-01 1.212e-01 7.784e-02 8.398e-02 1.127e-01 1.223e-01 1.277e-01\n",
      "  9.042e-02 1.127e-01 1.518e-01]\n",
      " [4.886e+00 5.012e+00 4.878e+00 4.652e+00 4.338e+00 4.321e+00 4.384e+00\n",
      "  4.450e+00 4.440e+00 3.792e+00]\n",
      " [4.886e+00 5.012e+00 4.878e+00 4.652e+00 4.338e+00 4.321e+00 4.384e+00\n",
      "  4.450e+00 4.440e+00 3.792e+00]\n",
      " [3.277e+00 3.596e+00 3.890e+00 3.844e+00 3.542e+00 3.410e+00 3.328e+00\n",
      "  3.506e+00 3.162e+00 2.884e+00]\n",
      " [4.341e-01 3.393e-01 2.662e-01 2.786e-01 3.254e-01 3.393e-01 3.469e-01\n",
      "  2.857e-01 3.143e-01 3.750e-01]\n",
      " [8.937e-01 8.001e-01 7.982e-01 8.292e-01 8.417e-01 8.451e-01 8.544e-01\n",
      "  8.408e-01 7.722e-01 8.189e-01]\n",
      " [1.534e+04 2.533e+04 2.817e+04 2.712e+04 2.505e+04 2.412e+04 2.225e+04\n",
      "  2.416e+04 2.827e+04 2.409e+04]\n",
      " [1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "  1.000e+00 1.000e+00 1.000e+00]\n",
      " [3.025e+00 3.300e+00 3.518e+00 3.569e+00 3.321e+00 3.282e+00 3.209e+00\n",
      "  3.473e+00 3.064e+00 2.834e+00]\n",
      " [9.094e+03 1.722e+04 1.761e+04 1.529e+04 1.431e+04 1.392e+04 1.284e+04\n",
      "  1.382e+04 1.975e+04 1.587e+04]\n",
      " [4.676e-01 3.622e-01 2.839e-01 2.954e-01 3.469e-01 3.500e-01 3.574e-01\n",
      "  2.957e-01 3.159e-01 3.781e-01]\n",
      " [1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "  1.000e+00 1.000e+00 1.000e+00]\n",
      " [3.201e+00 3.352e+00 3.613e+00 3.629e+00 3.358e+00 3.277e+00 3.257e+00\n",
      "  3.490e+00 3.084e+00 2.834e+00]\n",
      " [2.156e+04 1.487e+04 1.351e+04 1.216e+04 1.307e+04 1.475e+04 1.768e+04\n",
      "  1.906e+04 1.604e+04 2.206e+04]\n",
      " [1.028e+07 9.030e+06 9.067e+06 9.652e+06 9.964e+06 9.985e+06 9.923e+06\n",
      "  9.578e+06 8.869e+06 9.571e+06]\n",
      " [2.487e+09 2.111e+09 2.094e+09 2.243e+09 2.339e+09 2.355e+09 2.350e+09\n",
      "  2.250e+09 2.065e+09 2.272e+09]]\n",
      "Shape of GLCM feature vector: (20, 10)\n",
      "15-band DFT features:\n",
      " [[307.856]\n",
      " [139.549]\n",
      " [191.200]\n",
      " [ 73.845]\n",
      " [178.716]\n",
      " [123.570]\n",
      " [115.516]\n",
      " [ 76.518]\n",
      " [178.936]\n",
      " [ 84.732]\n",
      " [122.889]\n",
      " [ 42.417]\n",
      " [122.889]\n",
      " [ 84.732]\n",
      " [178.936]]\n",
      "Shape of DFT feature vector: (15, 1)\n",
      "2 features:\n",
      " [[1964.856]\n",
      " [   4.762]]\n",
      "2 features vector: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # img_path = \"/home/raginivi/Desktop/CV_project/saved_e/e_1.png\"  \n",
    "#     image_path = \"/home/raginivi/Desktop/CV_project/saved_e/e_1.png\"\n",
    "#     gray_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n",
    "    \n",
    "#     feature_20_glcm = get_all_glcm_features(image_path, 10, 256)\n",
    "    \n",
    "#     roi_mask = extract_roi(gray_img, threshold=128)\n",
    "#     b_vector = normalized_projection(gray_img, roi_mask)\n",
    "#     features_15_dft = dft_features(b_vector).reshape(-1,1)\n",
    "\n",
    "#     variance = compute_variance(gray_img, roi_mask)\n",
    "#     entropy = compute_entropy(gray_img, roi_mask)\n",
    "#     features_2_roi = np.array([[variance], [entropy]]) \n",
    "\n",
    "#     print(f\"Extracted GLCM feature vector: {feature_20_glcm}\")\n",
    "#     print(f\"Shape of GLCM feature vector: {np.shape(feature_20_glcm)}\")\n",
    "#     print(f\"15-band DFT features:\\n\", features_15_dft)\n",
    "#     print(f\"Shape of DFT feature vector: {np.shape(features_15_dft)}\")\n",
    "#     print(f\"2 features:\\n\", features_2_roi)\n",
    "#     print(f\"2 features vector: {np.shape(features_2_roi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ef2f12f5-5849-41b7-8ba0-1e63aabf88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features(image_paths, labels, save_dir):\n",
    "    \"\"\"\n",
    "    Extracts features from the provided image paths, processes them, \n",
    "    and stores them at the given save directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_paths: List of paths to the images.\n",
    "    - labels: List of corresponding class labels (integers).\n",
    "    - save_dir: Directory where the feature vectors will be saved.\n",
    "    \n",
    "    The function extracts a 22x10 feature vector for each character in an image\n",
    "    and saves them into a '.npz' file at the image's location.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the directory to save the features exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through each image and its corresponding label\n",
    "    for idx, (img_path, label) in enumerate(zip(image_paths, labels)):\n",
    "        # Step 1: Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if gray_img is None:\n",
    "            print(f\"Error: Unable to read image at {img_path}\")\n",
    "            continue  # Skip if image is not read successfully\n",
    "\n",
    "        # Step 2: Extract GLCM features (20x10 matrix)\n",
    "        feature_20_glcm = get_all_glcm_features(img_path, 10, 256)  # Assuming you have this function\n",
    "        # 'feature_20_glcm' is a 20x10 matrix, which will be the first part of the 22x10 feature vector\n",
    "\n",
    "        # Step 3: Extract ROI (Region of Interest) mask and DFT features\n",
    "        roi_mask = extract_roi(gray_img, threshold=128)  # Assuming you have this function\n",
    "        b_vector = normalized_projection(gray_img, roi_mask)  # Assuming this function returns a 1D vector\n",
    "        features_15_dft = dft_features(b_vector).reshape(15, 1)  # Assuming you have this function\n",
    "        # print(features_15_dft.shape)\n",
    "        \n",
    "        # Step 4: Compute ROI statistical features (variance and entropy)\n",
    "        variance = compute_variance(gray_img, roi_mask)  # Assuming you have this function\n",
    "        entropy = compute_entropy(gray_img, roi_mask)  # Assuming you have this function\n",
    "        features_2_roi = np.array([[variance], [entropy]])  # shape: (2, 1)\n",
    "\n",
    "        # Step 5: Combine all features into a final feature vector (22x10)\n",
    "        # 'glcm' (20x10), 'dft' (15x1), 'roi' (2x1) need to be combined\n",
    "        # Assuming we concatenate them along the appropriate axis to get a 22x10 array.\n",
    "        \n",
    "        # Combine features to get a 22x10 matrix:\n",
    "        combined_features = np.concatenate([\n",
    "            feature_20_glcm,                  # shape: (20, 10)\n",
    "            features_15_dft.repeat(10, axis=1),  # shape: (15, 10)\n",
    "            features_2_roi.repeat(10, axis=1) # shape: (2, 10) -- repeat to match 10 characters\n",
    "        ], axis=0)  # This will give us a shape of (22, 10)\n",
    "\n",
    "        save_path = os.path.join(save_dir, f'features_{idx:02d}.pkl')\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(combined_features, f) \n",
    "\n",
    "        print(f\"Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "25ff3dd7-690a-46ca-a45f-d8bab29e1717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('output_features/features_00.pkl', 'rb') as f:\n",
    "#     unpickled_features = pickle.load(f)\n",
    "\n",
    "# # Display the unpickled features (the 2D matrix)\n",
    "# print(\"Unpickled Features (Shape: {}):\".format(unpickled_features.shape))\n",
    "# print(unpickled_features)\n",
    "\n",
    "# # Optionally, if you want to display specific rows or columns:\n",
    "# print(\"\\nFirst Row:\")\n",
    "# print(unpickled_features[7])  # Display the first row\n",
    "\n",
    "# print(\"\\nFirst Column:\")\n",
    "# print(unpickled_features[:, 7])  # Display the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1b433480-2fca-496a-a676-43ba224a341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_00.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_01.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_02.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_03.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_04.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_05.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_06.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_07.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_08.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/1/ef/features_09.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_00.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_01.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_02.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_03.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_04.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_05.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_06.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_07.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_08.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/2/ef/features_09.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_00.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_01.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_02.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_03.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_04.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_05.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_06.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_07.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_08.pkl\n",
      "(1, 10) (1, 10) (1, 10) (1, 10)\n",
      "(15, 1)\n",
      "Saved: /home/raginivi/Desktop/CV_project/saved_e/3/ef/features_09.pkl\n"
     ]
    }
   ],
   "source": [
    "def process_directories(input_dirs, save_base_dir):\n",
    "    \"\"\"\n",
    "    Process all images in the input directories, extract features, and save them.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dirs: List of directories to process (each directory is a class).\n",
    "    - save_base_dir: Base directory where the feature files will be stored.\n",
    "    \"\"\"\n",
    "    for class_dir in input_dirs:\n",
    "        # Get the class label (the name of the directory)\n",
    "        class_label = os.path.basename(class_dir)\n",
    "        \n",
    "        # Create a subdirectory called 'ef' inside the current class directory\n",
    "        save_dir = os.path.join(class_dir, 'ef')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all image paths in the current class directory\n",
    "        image_paths = []\n",
    "        labels = []  # List of class labels corresponding to images\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):  # Ensure only image files are processed\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(class_label)  # Using directory name as the label\n",
    "        \n",
    "        # Call function to extract features and save them\n",
    "        extract_and_save_features(image_paths, labels, save_dir)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_dirs = ['/home/raginivi/Desktop/CV_project/saved_e/1', '/home/raginivi/Desktop/CV_project/saved_e/2'\n",
    "              , '/home/raginivi/Desktop/CV_project/saved_e/3']  # Replace with your actual directories\n",
    "save_base_dir = 'extracted_features'  # Where the features will be saved\n",
    "\n",
    "process_directories(input_dirs, save_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fbe6b-89c0-4460-b906-5c89f9522bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
