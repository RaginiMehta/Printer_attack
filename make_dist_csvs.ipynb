{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f0322c-3692-4d34-8ae6-ad9f12a228c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so starrting off, we are gonna check how the data is stored\n",
    "# we have 22x10 sized feature vector of all the training sample's e's and so lets say that there are 50 e's, \n",
    "# so there are 50 22x10 vectors supposed to be stored \n",
    "\n",
    "# tho we ahve stored only 10 e's, we can store more obviously, this will help with wrong e's as well\n",
    "\n",
    "# now, we will unpickle the e vectors, store each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd9aa79-183e-49a7-9411-d137081ee65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas not found. Installing pandas...\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/raginivi/anaconda3/envs/ml/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/raginivi/anaconda3/envs/ml/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/raginivi/anaconda3/envs/ml/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m25.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Function to install pandas if not already installed\n",
    "def install_pandas():\n",
    "    try:\n",
    "        import pandas\n",
    "        print(\"pandas is already installed.\")\n",
    "    except ImportError:\n",
    "        print(\"pandas not found. Installing pandas...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\"])\n",
    "\n",
    "# Install pandas\n",
    "install_pandas()\n",
    "\n",
    "# After installation, import pandas and proceed with the rest of your script\n",
    "import pandas as pd\n",
    "\n",
    "# Now, you can use pandas as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1376d-4105-434d-8f5c-253ec1c3ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this much is to make csv's based on distances\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder paths where your pickle files are stored\n",
    "folder_paths = ['saved_e/1/ef', 'saved_e/2/ef', 'saved_e/3/ef', 'saved_e/4/ef', 'saved_e/5/ef']\n",
    "output_folder = 'dist_csvs' \n",
    "\n",
    "# List to hold the 10 columns' data\n",
    "columns_data = {i: [] for i in range(10)}  # For 10 columns, index 0 to 9\n",
    "\n",
    "# Iterate over each folder\n",
    "for folder_path in folder_paths:\n",
    "    pickle_file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.pkl')]\n",
    "\n",
    "    # Iterate over each pickle file in the current folder\n",
    "    for file_path in pickle_file_paths:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            array = pickle.load(f)\n",
    "            for col in range(10):  # Assuming arrays have 10 columns\n",
    "                columns_data[col].append(array[:, col])\n",
    "\n",
    "# Now, columns_data holds 10 lists of arrays, each of shape (150,)\n",
    "# Convert each list of column values into a 150xN matrix (where N = 150)\n",
    "for col, data in columns_data.items():\n",
    "    # Stack the data vertically to get a (150, 150) matrix for each column\n",
    "    column_matrix = np.column_stack(data)\n",
    "    \n",
    "    # Transpose the matrix to make it (150, 10)\n",
    "    column_matrix = column_matrix.T  # Now it's of shape (10, 150)\n",
    "    \n",
    "    # Convert it to a pandas DataFrame for easier CSV export\n",
    "    df = pd.DataFrame(column_matrix)\n",
    "    \n",
    "    # Save to CSV, name the file based on the column index\n",
    "    # df.to_csv(f'column_{col+1}.csv', index=False, header=False)\n",
    "    df.to_csv(os.path.join(output_folder, f'column_{col+1}.csv'), index=False, header=False)\n",
    "\n",
    "print(\"All CSV files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dedfb5-1dbb-4648-b7af-0e84a1eb52ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder paths where your pickle files are stored\n",
    "folder_paths = ['Testing_attacked/1.0.png/ef',\n",
    "                'Testing_attacked/1.1.png/ef',\n",
    "                'Testing_attacked/1.3.png/ef',\n",
    "                'Testing_attacked/1.4.png/ef',\n",
    "                'Testing_attacked/1.6.png/ef',\n",
    "                'Testing_attacked/2.0.png/ef',\n",
    "                'Testing_attacked/2.1.png/ef',\n",
    "                'Testing_attacked/2.3.png/ef',\n",
    "                'Testing_attacked/2.4.png/ef',\n",
    "                'Testing_attacked/2.6.png/ef',\n",
    "                'Testing_attacked/3.0.png/ef',\n",
    "                'Testing_attacked/3.1.png/ef',\n",
    "                'Testing_attacked/3.3.png/ef',\n",
    "                'Testing_attacked/3.4.png/ef',\n",
    "                'Testing_attacked/3.6.png/ef',\n",
    "                'Testing_attacked/4.0.png/ef',\n",
    "                'Testing_attacked/4.1.png/ef',\n",
    "                'Testing_attacked/4.3.png/ef',\n",
    "                'Testing_attacked/4.4.png/ef',\n",
    "                'Testing_attacked/4.6.png/ef']\n",
    "output_folder = 'dist_attacked_csvs' \n",
    "\n",
    "# List to hold the 10 columns' data\n",
    "columns_data = {i: [] for i in range(10)}  # For 10 columns, index 0 to 9\n",
    "\n",
    "# Iterate over each folder\n",
    "for folder_path in folder_paths:\n",
    "    pickle_file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.pkl')]\n",
    "\n",
    "    # Iterate over each pickle file in the current folder\n",
    "    for file_path in pickle_file_paths:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            array = pickle.load(f)\n",
    "            for col in range(10):  # Assuming arrays have 10 columns\n",
    "                columns_data[col].append(array[:, col])\n",
    "\n",
    "# Now, columns_data holds 10 lists of arrays, each of shape (150,)\n",
    "# Convert each list of column values into a 150xN matrix (where N = 150)\n",
    "for col, data in columns_data.items():\n",
    "    # Stack the data vertically to get a (150, 150) matrix for each column\n",
    "    column_matrix = np.column_stack(data)\n",
    "    \n",
    "    # Transpose the matrix to make it (150, 10)\n",
    "    column_matrix = column_matrix.T  # Now it's of shape (10, 150)\n",
    "    \n",
    "    # Convert it to a pandas DataFrame for easier CSV export\n",
    "    df = pd.DataFrame(column_matrix)\n",
    "    \n",
    "    # Save to CSV, name the file based on the column index\n",
    "    # df.to_csv(f'column_{col+1}.csv', index=False, header=False)\n",
    "    df.to_csv(os.path.join(output_folder, f'column_{col+1}.csv'), index=False, header=False)\n",
    "\n",
    "print(\"All CSV files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbccaa2-4748-4286-a417-9208426ae160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'output.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# to make the class wala csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create the list of values\n",
    "values = ['A'] * 50 + ['B'] * 50 + ['C'] * 50 + ['D'] * 50 + ['E'] * 50\n",
    "\n",
    "# Convert the list into a pandas DataFrame\n",
    "df = pd.DataFrame(values, columns=['Column1'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('class_label.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'output.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ed2bc4-c1c5-4d22-987d-728ac5b686f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: dist_attacked_csvs\n",
      "Empty CSV file created at: dist_attacked_csvs/attack_file_1.csv\n",
      "Empty CSV file created at: dist_attacked_csvs/attack_file_2.csv\n",
      "Empty CSV file created at: dist_attacked_csvs/attack_file_3.csv\n",
      "Empty CSV file created at: dist_attacked_csvs/attack_file_4.csv\n",
      "Empty CSV file created at: dist_attacked_csvs/attack_file_5.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'dist_attacked_csvs'  \n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Created the directory: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {folder_path}\")\n",
    "\n",
    "# Create 5 empty CSV files\n",
    "for i in range(1, 6):\n",
    "    # Define the file name for each CSV\n",
    "    file_name = f\"attack_file_{i}.csv\"\n",
    "    \n",
    "    # Path to save the empty CSV file\n",
    "    csv_file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Save the empty DataFrame to CSV\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Empty CSV file created at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b7b26-a429-4afc-b939-091892023b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
